{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45189bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nigel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nigel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nigel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nigel\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# download punctuation and stopwords from nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32537156",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"Resources/Tweets.csv\")\n",
    "# make sure the tweets in column \"text\" are strings\n",
    "tweets_df['text'] = tweets_df['text'].astype('str')\n",
    "\n",
    "# delete the unneccessary columns\n",
    "tweets_df = tweets_df.drop(columns=[\"textID\", \"selected_text\"])\n",
    "tweets_df=tweets_df.rename(columns={'sentiment':'class'})\n",
    "tweets_df=tweets_df[['text','class']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "709decfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_process_tweets(tweet):\n",
    "    # make the text all lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # remove punctuation\n",
    "    tweet = \"\".join(char for char in tweet if char not in string.punctuation)\n",
    "  \n",
    "    # remove urls\n",
    "    tweet_wo_stop = \"\".join([i for i in tweet if 'http' not in i])\n",
    "    \n",
    "    \n",
    "    # lemmatization\n",
    "    lemm = WordNetLemmatizer()\n",
    "    lemmed = [lemm.lemmatize(word) for word in tweet_wo_stop]\n",
    "    \n",
    "    # put string together\n",
    "    final_tweet = \"\".join(lemmed)\n",
    "    \n",
    "    return final_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b592485e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     class\n",
       "0                      id have responded if i were going   neutral\n",
       "1             sooo sad i will miss you here in san diego  negative\n",
       "2                                 my boss is bullying me  negative\n",
       "3                          what interview leave me alone  negative\n",
       "4       sons of  why couldnt they put them on the rel...  negative\n",
       "...                                                  ...       ...\n",
       "27476   wish we could come see u on denver  husband l...  negative\n",
       "27477   ive wondered about rake to  the client has ma...  negative\n",
       "27478   yay good for both of you enjoy the break  you...  positive\n",
       "27479                              but it was worth it    positive\n",
       "27480     all this flirting going on  the atg smiles ...   neutral\n",
       "\n",
       "[27481 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['text'] = tweets_df['text'].apply(lambda x: nb_process_tweets(x))\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b41f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sentiment = {'positive': 2, 'neutral': 0, 'negative': 1}\n",
    "tweets_df['class'] = tweets_df['class'].apply(lambda x: dict_sentiment.get(x))\n",
    "targets=pd.get_dummies(tweets_df,prefix=\"\",prefix_sep='',columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc69206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = targets.sample(frac=0.8)\n",
    "test=targets.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "482b03bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d00d75486b04a31b5986e85a81b613e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nigel\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nigel\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954299c4465548f98c5ad6328a413305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7cbf45dda44901a78d4d6e2a9eb80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4dd1e3070e74a16a1f063f820f82089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc634e52508a4ea58f326602dacfbe1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nigel\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:612: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d901de4f194446a32fb61e2c6c43b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b490b87a0a49ce889587e43b892429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001cc66738d4c2b9c74dc3d5d269373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/2749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac715eab6414bdcbae158f94f695471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/2749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5498, 0.4416525525763555)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "model = ClassificationModel('bert', 'bert-base-uncased', use_cuda=False,args={\n",
    "                                                                                             'reprocess_input_data': True,\n",
    "                                                                                             'overwrite_output_dir': True,\n",
    "                                                                                             'fp16': False,\n",
    "                                                                                             'do_lower_case': False,\n",
    "                                                                                             'num_train_epochs': 2,\n",
    "                                                                                             \n",
    "                                                                                             'regression': False,\n",
    "                                                                                      \n",
    "                                                                                             \"learning_rate\":4e-5,\n",
    "                                                                                             'weight_decay':0.0,\n",
    "                                                                                             \"save_eval_checkpoints\": False,\n",
    "                                                                                             \"save_model_every_epoch\": False,\n",
    "                                                                                             \"silent\": False})\n",
    "\n",
    "model.train_model(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6baaa7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nigel\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:1454: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b7917851f144839e36fec2e987e6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5496 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67a6b8f713b4a7e9b3b8daa719e4e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "test_result, test_model_outputs, test_wrong_predictions = model.eval_model(test,acc=accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6355abc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': 0.5807640123331936, 'tp': 1630, 'tn': 2762, 'fp': 515, 'fn': 589, 'auroc': 0.8743084628646844, 'auprc': 0.8265223972774384, 'acc': 0.7991266375545851, 'eval_loss': 0.5038491542704587}\n"
     ]
    }
   ],
   "source": [
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa4e7c",
   "metadata": {},
   "source": [
    "# Optimized\n",
    "Removing neutral sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01d013e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_df = pd.read_csv(\"Resources/Tweets.csv\")\n",
    "optimized_df=optimized_df.loc[optimized_df['sentiment']!=\"neutral\"]\n",
    "# optimized_df=optimized_df.dropna()\n",
    "optimized_df\n",
    "optimized_df['text'] = optimized_df['text'].astype('str')\n",
    "\n",
    "# delete the unneccessary columns\n",
    "optimized_df = optimized_df.drop(columns=[\"textID\", \"selected_text\"])\n",
    "optimized_df=optimized_df.rename(columns={'sentiment':'class'})\n",
    "optimized_df=optimized_df[['text','class']]\n",
    "optimized_df['text'] = optimized_df['text'].apply(lambda x: nb_process_tweets(x))\n",
    "optimized_df\n",
    "dict_sentiment = {'positive': 0,'negative': 1}\n",
    "optimized_df['class'] = optimized_df['class'].apply(lambda x: dict_sentiment.get(x))\n",
    "opt_targets=pd.get_dummies(optimized_df,prefix=\"\",prefix_sep='',columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adbe8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_train = opt_targets.sample(frac=0.8)\n",
    "opt_test=opt_targets.drop(opt_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "456c9cf8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nigel\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:612: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a81949945b47b1b0ffabdad3a0db92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501da87c01574d5096902603ed0e6d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e76aaf476a547469ea40d71e6d7515c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/1637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f701d1361944ba8bb3ea4b4d3f530d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/1637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3274, 0.23010731098924736)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "opt_model = ClassificationModel('bert', 'bert-base-uncased', use_cuda=False,args={\n",
    "                                                                                             'reprocess_input_data': True,\n",
    "                                                                                             'overwrite_output_dir': True,\n",
    "                                                                                             'fp16': False,\n",
    "                                                                                             'do_lower_case': False,\n",
    "                                                                                             'num_train_epochs': 2,\n",
    "                                                                                             \n",
    "                                                                                             'regression': False,\n",
    "                                                                                      \n",
    "                                                                                             \"learning_rate\":4e-5,\n",
    "                                                                                             'weight_decay':0.0,\n",
    "                                                                                             \"save_eval_checkpoints\": False,\n",
    "                                                                                             \"save_model_every_epoch\": False,\n",
    "                                                                                             \"silent\": False})\n",
    "\n",
    "opt_model.train_model(opt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cae042fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nigel\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:1454: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0176f14dfa9f4931bb43a5e923a5c297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8851e2524b4b4529955c900c5414b46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "opt_test_result, opt_test_model_outputs, opt_test_wrong_predictions = opt_model.eval_model(opt_test,acc=accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c04c42ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcc': 0.861698050255382,\n",
       " 'tp': 1598,\n",
       " 'tn': 1449,\n",
       " 'fp': 102,\n",
       " 'fn': 124,\n",
       " 'auroc': 0.9793138591789343,\n",
       " 'auprc': 0.9811517095005018,\n",
       " 'acc': 0.9309501985945615,\n",
       " 'eval_loss': 0.29111145737314054}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d8d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
